{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb385296",
   "metadata": {},
   "source": [
    "#Start Dates\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date(2021, 12, 1)\n",
    "delta = datetime.timedelta(days=25)\n",
    "\n",
    "start_list =[]\n",
    "\n",
    "while start_date <= end_date:\n",
    "    start_list.append(start_date)\n",
    "    start_date += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d71d86",
   "metadata": {},
   "source": [
    "#End Dates\n",
    "start_date = datetime.date(2021, 1, 26)\n",
    "end_date = datetime.date(2021, 12, 1)\n",
    "delta = datetime.timedelta(days=25)\n",
    "\n",
    "end_list =[]\n",
    "\n",
    "while start_date <= end_date:\n",
    "    end_list.append(start_date)\n",
    "    start_date += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04cd2a",
   "metadata": {},
   "source": [
    "#Converting lists to strings \n",
    "end_str_list = []\n",
    "for i in range(0,len(end_list)):\n",
    "    end_str_list.append(end_list[i].strftime('%Y%m%d'))\n",
    "    \n",
    "start_str_list =[]\n",
    "for i in range(0,len(start_list)):\n",
    "    start_str_list.append(start_list[i].strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b9907",
   "metadata": {},
   "source": [
    "# Code for 2021 data\n",
    "start_list = pd.date_range(start='1/1/2021', end ='1/1/2022', freq='MS')\n",
    "\n",
    "start_str_list = []\n",
    "end_str_list = []\n",
    "for date in start_list:\n",
    "    start_str_list.append(date.strftime('%Y%m%d'))\n",
    "    end_str_list.append(date.strftime('%Y%m%d'))\n",
    "\n",
    "start_str_list = start_str_list[0:12]\n",
    "end_str_list = end_str_list[1:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51917ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 60 days' retro data\n",
    "today = pd.to_datetime(\"today\") + datetime.timedelta(days=1)  \n",
    "\n",
    "start_str_list = []\n",
    "end_str_list = []\n",
    "\n",
    "retro_start = 60\n",
    "retro_end = 30\n",
    "\n",
    "# For start dates\n",
    "for x in range(0,2):\n",
    "    if retro_start >= 0:\n",
    "        start = today - datetime.timedelta(days=retro_start)\n",
    "        start_str_list.append(start.strftime('%Y%m%d'))\n",
    "        retro_start -=30\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# For end dates\n",
    "for y in range(0,1):\n",
    "    if retro_end > 0:\n",
    "        end = today - datetime.timedelta(days=retro_end)\n",
    "        end_str_list.append(end.strftime('%Y%m%d'))        \n",
    "        retro_end -=30\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "end_str_list.append(today.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c305123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of endpoints for API\n",
    "complete_endpoints = []\n",
    "for i in range(0,len(start_str_list)):\n",
    "    complete_endpoints.append(f\"{start_str_list[i]}:{end_str_list[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base URL setup\n",
    "base_url = \"https://www.ncdc.noaa.gov/swdiws/json/nx3tvs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all URLs\n",
    "all_urls = []\n",
    "for dates in complete_endpoints:\n",
    "    complete_url = base_url + dates\n",
    "    all_urls.append(complete_url)\n",
    "#print(len(all_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e981b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List/Variables setup\n",
    "cell_type =[]\n",
    "shape =[]\n",
    "max_shear = []\n",
    "wsr_id =[]\n",
    "mxdv = []\n",
    "cell_id =[]\n",
    "ztime = []\n",
    "azimuth = []\n",
    "range_ = []\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "#url_counter = 1\n",
    "\n",
    "# Start of Log\n",
    "print(\"-----------------------------\")\n",
    "print(\"Beginning Data Retrieval - estimated time is <5min\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "#----BEGIN Loop----\n",
    "# Looping through urls and appending data to lists\n",
    "for url in all_urls:\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "        for i in range(len(response[\"result\"])):\n",
    "            cell_type.append(response[\"result\"][i][\"CELL_TYPE\"])\n",
    "            shape.append(response[\"result\"][i][\"SHAPE\"])\n",
    "            max_shear.append(response[\"result\"][i][\"MAX_SHEAR\"])\n",
    "            wsr_id.append(response[\"result\"][i][\"WSR_ID\"])\n",
    "            mxdv.append(response[\"result\"][i][\"MXDV\"])\n",
    "            cell_id.append(response[\"result\"][i][\"CELL_ID\"])\n",
    "            ztime.append(response[\"result\"][i][\"ZTIME\"])\n",
    "            azimuth.append(response[\"result\"][i][\"AZIMUTH\"])\n",
    "            range_.append(response[\"result\"][i][\"RANGE\"])\n",
    "            lon.append(response[\"result\"][i][\"SHAPE\"].split()[1:][0].split('(')[1])\n",
    "            lat.append(response[\"result\"][i][\"SHAPE\"].split()[1:][1].split(')')[0])\n",
    "            #print(f\"Processing Record {i} of URL {url_counter}\")\n",
    "        #url_counter += 1\n",
    "    \n",
    "    except(KeyError, IndexError):\n",
    "        print(f\"URL {url} not found. Skipping...\")\n",
    "\n",
    "#----END Loop-----\n",
    "\n",
    "# End of Log\n",
    "print(\"-----------------------------\")\n",
    "print(\"Data Retrieval Complete\")\n",
    "print(\"-----------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29580504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe of all records\n",
    "dict = {\"Cell_Type\": cell_type,\n",
    "        \"Shape\": shape,\n",
    "        \"Max_Shear\": max_shear,\n",
    "        \"WSR_ID\": wsr_id,\n",
    "        \"MXDV\": mxdv,\n",
    "        \"Cell_ID\": cell_id,\n",
    "        \"zTime\": ztime,\n",
    "        \"Azimuth\": azimuth,\n",
    "        \"Range\": range_,\n",
    "        \"Lat\": lat,\n",
    "        \"Lon\": lon\n",
    "       }\n",
    "\n",
    "dict[\"zTime\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fca56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating additional columns\n",
    "# df['Date']=pd.to_datetime(df['zTime']).dt.date\n",
    "# df['Time']=pd.to_datetime(df['zTime']).dt.time\n",
    "# df['Year']=pd.to_datetime(df['zTime']).dt.year\n",
    "# df['Month']=pd.to_datetime(df['zTime']).dt.month\n",
    "\n",
    "date = []\n",
    "time = []\n",
    "year = []\n",
    "month = []\n",
    "for x in ztime:\n",
    "    date.append(datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n",
    "    time.append(datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').time())\n",
    "    year.append(datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').year)\n",
    "    month.append(datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').month)\n",
    "dict['Date']= date\n",
    "dict['Time']= time\n",
    "dict['Year']= year\n",
    "dict['Month']= month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33722ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primary Key to id tornados\n",
    "#df['PKID']=df['Cell_ID']+df['zTime'].astype(str)\n",
    "#df.head()\n",
    "\n",
    "pkid = []\n",
    "for x in range(len(cell_id)):\n",
    "    pkid.append(cell_id[x] + ztime[x])\n",
    "dict['PKID'] = pkid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceaa825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = dict.sort_values(['Date','Time'], ascending = [True,True])\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074d16b",
   "metadata": {},
   "source": [
    "#Function to build geojson\n",
    "def df_to_geojson(df, properties, lat='Lat', lon='Lon'):\n",
    "    #Create a new python dict to contain our geojson data, using geojson format\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "\n",
    "    #Loop through each row in the dataframe and convert each row to geojson format\n",
    "    for _, row in df.iterrows():\n",
    "        #Create a feature template to fill in\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "\n",
    "        #Fill in the coordinates\n",
    "        feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "\n",
    "        #For each column, get the value and add it as a new feature property\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        \n",
    "        #Add this feature (aka, converted dataframe row) to the list of features inside our dict\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c0f4c",
   "metadata": {},
   "source": [
    "# Setting columns and running function\n",
    "cols = [\"Cell_Type\", \"Shape\", \"Max_Shear\", \n",
    "        \"WSR_ID\", \"MXDV\", \"Cell_ID\", \n",
    "        \"zTime\", \"Azimuth\", \"Range\", \"Lat\", \"Lon\",\n",
    "        \"Date\",\"Time\",\"Year\",\"Month\",\"PKID\"]\n",
    "geojson = df_to_geojson(df, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bffa5e",
   "metadata": {},
   "source": [
    "#Saving output into js file\n",
    "output_filename = 'static/data/tornadoes.geojson'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    json.dump(geojson, output_file, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('static/data/tornadoes.json', orient = 'records', compression = 'infer', index = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c226f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData38] *",
   "language": "python",
   "name": "conda-env-PythonData38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
